```{bash}

#basecalling with Guppy on pass and fail fast5s for both 'sample' locations
~/ont-guppy/bin/guppy_basecaller --input_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fast5_pass/ --save_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd --calib_detect --config dna_r10.4_e8.1_hac.cfg -x cuda:0 --num_callers 8

~/ont-guppy/bin/guppy_basecaller --input_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fast5_fail/ --save_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd --calib_detect --config dna_r10.4_e8.1_hac.cfg -x cuda:0 --num_callers 8

~/ont-guppy/bin/guppy_basecaller --input_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fast5_pass/ --save_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd --calib_detect --config dna_r10.4_e8.1_hac.cfg -x cuda:0 --num_callers 8

~/ont-guppy/bin/guppy_basecaller --input_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fast5_fail/ --save_path /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd --calib_detect --config dna_r10.4_e8.1_hac.cfg -x cuda:0 --num_callers 8

#read splitting
#to install duplex tools:
python -m venv venv --prompt duplex
. venv/bin/activate
pip install duplex_tools

#to reactivate later:
. ~/venv/bin/activate

#split_on_adapter for both basecalled 'samples'
duplex_tools split_on_adapter /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/pass /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/split_pass PCR
#output: 444it [00:18, 23.82it/s]
#Split 78903 reads kept 1309065 reads

duplex_tools split_on_adapter /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd/pass /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd/split_pass PCR
#output: 455it [00:19, 23.62it/s]
#Split 81684 reads kept 1335664 reads

#demultiplexing:
~/ont-guppy/bin/guppy_barcoder --require_barcodes_both_ends -i /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/split_pass -s /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/demultiplexed_split_pass --arrangements_files "barcode_arrs_pcr12.cfg barcode_arrs_pcr96.cfg" -x cuda:0 --worker_threads 8


~/ont-guppy/bin/guppy_barcoder --require_barcodes_both_ends -i /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd/split_pass -s /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd/demultiplexed_split_pass --arrangements_files "barcode_arrs_pcr12.cfg barcode_arrs_pcr96.cfg" -x cuda:0 --worker_threads 8



combine both 'runs'
(base) user@user-System-Product-Name:/mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd/demultiplexed_split_pass$ 
for i in ./barcode*;
do bn=$(basename $i );
cp ${bn}/*.fastq ../../../../20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/demultiplexed_split_pass/${bn}/;
done

#no barcode 68
(base) user@user-System-Product-Name:/mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/no_sample/20211217_1150_MN23913_FAR27359_a1bdbce7/fastq_hac_cd/demultiplexed_split_pass$ cp ./barcode68 ../../../../20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/demultiplexed_split_pass/

#now work in /mnt/data0/MinION_reads/pitesky_avian_samples1_cp/pitesky_avian_samples1/20211216_1317_MN23913_FAR27359_f42a3dea/fastq_hac_cd/demultiplexed_split_pass
#convert to fasta
for i in barcode*/*.fastq; do sed -n '1~4s/^@/>/p;2~4p' $i > $i.fasta; done

#make one fasta for each barcode
for i in barcode*;
do bn=$(basename $i);
cat ./${bn}/*.fasta >> ./${bn}/${bn}.fasta;
done

#mv to analysis dir
for i in barcode*;
do bn=$(basename $i);
mv ./${bn}/${bn}.fasta ~/Documents/CM_aiv_detection_environment/;
done


#generate report - ?
wc -l *.fasta | awk '{print $1/2" " $2}' | sed '$d'  >> demultiplexing_by_sample.txt

#make blast database
makeblastdb -in AllFluGenomicFastaResults.fasta -dbtype nucl -out new_all_avian_flu

#from aiv script:
#This command uses GNU parallel to conduct BLAST searches in parallel for each demultiplexed file
#First looking at forward read files
ls forward_*.fasta | awk -F'[.]' '{print $1}'| parallel -j+0 --eta 'blastn -db all_avian_flu -query {.}.fasta -out {.}.out  -max_target_seqs 1 -outfmt 6'


#for loop blast code ... not parallel though...
for i in barcode*.fasta; 
do bn=$(basename $i .fasta)
blastn -db new_all_avian_flu -query ${bn}*.fasta -out ${bn}.out -max_target_seqs 1 -outfmt 6';
done


#final blast code:
ls barcode*.fasta | awk -F'[.]' '{print $1}'| parallel -j+0 --eta 'blastn -db new_all_avian_flu -query {.}.fasta -out {.}.out  -max_target_seqs 1 -outfmt 6'
 

#SKIP: Export info to our running report
#wc -l *.out >> demultiplexing_assignment_report.txt

#Now add the number of reads matching the avian flu database to the file avian_blast_matches.txt
wc -l *.out | awk '{print $1" " $2}' | sed '$d' > avian_blast_matches.txt


#for all of them:


#Finally look up metadata for the closest blast matches for each read
#Now use the .out files to generate a list of GI's to lookup against database

for file in *.out; 
do awk '{print $2}' $file | awk -F ":" '{print $2}' | awk -F "|" '{print $1}' > ${file%.out}.tmp;
done

#Use that file to get matches from the database
for file in *.tmp; 
do grep -f $file data/AllFluGenomicFastaResults.fasta > "${file%.out}.tab";
done









rename *.out files:

while read -r line; do
   value1=$(echo "$line"| awk -F" "  '{print $1}')
   value2=$(echo "$line"| awk -F" "  '{print $2}')
   cp ${value1}.out ${value2}.out
done < renaming.csv





```
